\documentclass[11pt]{article}
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}  % \includegraphics[scale=0.6]{image.png}\\
\usepackage{color}  % \textcolor{declared-color}{text}
\usepackage{mdframed}  % Cadres de couleurs \begin{mdframed}[linecolor=...] \end{mdframed}
\usepackage{amsfonts}  % Pour écrire les ensembles IR, IK etc "\mathbb  "
\usepackage{amsmath}  % Utilisation de \underset
\usepackage{amssymb}  % Utilisation de \underset
\usepackage{hyperref}  % Mettre le lien vers la page de google drive
\usepackage{times}
\usepackage{fullpage}

\title{Résumé cours de Maths - 2eme Session\\ \textbf{Algèbre Linéaire}}

\pagestyle{plain}

\begin{document}
    \pagenumbering{Roman}
    \maketitle
    \tableofcontents
    \pagebreak
    \textbf{Contacts: \\Henri Anciaux} \\
    Mail : \textcolor{blue}{henri.anciaux@gmail.com} \\ % Les liens hyper-textes se font automatiquement
    Site : \textcolor{blue}{http://homepages.ulb.ac.be/hanciaux/MATHF112.html} \\
    Bureau : P.O.7.110\\
    \\
    Lien de partage (Google Drive) des scans du cours théorique :\\
    \urlstyle{same}
    \textcolor{blue}{\href{https://drive.google.com/open?id=0B11b8daV9oclfllIMjFsNktRblMzdFdXM3cxazVtUGpqYlY2VHFvaV8tQWlRZEM4VDc2MG8&authuser=0} {LIEN - Cours théorique}}\\

    \clearpage
    \setcounter{page}{1}
    
    \pagenumbering{arabic}
    \pagebreak

    \section{Introduction à l'algèbre linéaire}
        On retrouve l'algèbre linéaire aussi nombreux que varié dans les mathématiques.
        Et elle nous permet de pouvoir \textbf{simplifier les choses}. \\
        \includegraphics[scale=0.6]{figures/graphiques-fonctions.png} \\
        $f(x+h) \approx f(x)+h \times f'(x)$ (linéaire)
        
        Par exemple le Polynôme de Taylor (qui est un cas d'algèbre linéaire)
        nous permet de simplifier des expressions mathématiques en les linéarisant
        et donc de pouvoir résoudre certains calculs insolubles sans. Comme la
        formule d'oscillation du pendule: $y'' + \sin(y) = 0$ qui est une équation
        différentielle du second ordre impossible à résoudre, peut être simplifiée en $y''+y=0$.
        Elle est aussi utile dans les nuages de points, pour calculer une
        matrice puissance $n$, approximer des fonctions, etc...

    \section{Vecteurs}
    
        \subsection{Espace vectoriel}  % Espace vectoriel
        
            \begin{mdframed}[linecolor=magenta]
                \textcolor{magenta}{\textbf{Notation :}} \\
                $\mathbb K = \mathbb R, \mathbb C$, $\{0, 1\}$ ou n'importe quel "corps".
            \end{mdframed}

            \begin{mdframed}[linecolor=blue]
                \textcolor{blue}{\textbf{Définition :}}\\
                Un \textbf{espace vectoriel} sur $\mathbb K$ ( = "$\mathbb K$-espace vectoriel")
                est un ensemble E muni de 2 opérations:
                \begin{itemize}
                    \item \textbf{addition interne} : $+ : E \times E \to E$
                    telle que, $\forall \, u, v, w \in E$ :
                    \begin{enumerate}
                        \item + est \textbf{commutative} $\Leftrightarrow v + w = w + v$
                        \item + est \textbf{associative} $\Leftrightarrow u + (v + w) = (u + v) + w$
                        \item + admet un \textbf{élément neutre} noté $\overrightarrow{0_E}$ ou $0 \Leftrightarrow 0 + v = v$
                        \item + admet un \textbf{opposé} noté $-v \Leftrightarrow v + (-v) = 0$
                    \end{enumerate}
                  
                  \item \textbf{Multiplication externe} : $\cdot: \mathbb K\times E \to E$
                  telle que, $\forall \lambda \, \in \mathbb K, v, w \, \in E$:
                    \begin{enumerate}
                        \item $\cdot$ est \textbf{distributive à gauche}
                              $\Leftrightarrow \lambda \cdot (v + w) = \lambda \cdot v + \lambda \cdot w$
                        \item $\cdot$ est \textbf{distributive à droite}
                              $\Leftrightarrow (v + w) \cdot \lambda = \lambda \cdot v + \lambda \cdot w$
                        \item $\cdot$ est \textbf{associative}
                              $\Leftrightarrow \lambda \cdot (\mu \cdot v) = (\lambda \cdot \mu) \cdot v$
                        \item $\cdot$ admet un \textbf{élément neutre}
                              $\Leftrightarrow 1 \cdot v = v$
                   \end{enumerate}
                \end{itemize}
                Les éléments de E sont appelés vecteurs. Les 2 opérations + et $\cdot$
                constituent une structure vectorielle.
            \end{mdframed}

            \begin{mdframed}[linecolor=cyan]
            \textcolor{cyan}{\textbf{Remarque :}}\\
                Si E est un e.v. (= Espace Vectoriel),
                
                \[
                    \left \{
                        \begin{aligned}
                            0 \cdot v &= \overrightarrow{0_E} \\
                            (-1) \cdot v &= (-v)
                        \end{aligned}
                    \right.
                \]
            \end{mdframed}

            \begin{mdframed}[linecolor=magenta]
                \textcolor{magenta}{\textbf{Notation :}}\\
                On appelle \textbf{scalaire} tout élément de $\mathbb K$
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
                \textcolor{red}{\textbf{Théorème :}}\\
                 $\mathbb K^n$ est un $\mathbb K$-e.v. (par exemple $\mathbb R^n$ ou $\mathbb C^n$)
            \end{mdframed}
            
            \bigskip
            
            3 concepts fondamentaux :
            
            \begin{enumerate}
                \item \textbf{Applications linéaires}
                \item \textbf{Sous-espaces vectoriels}
                \item \textbf{Base et dimensions}
            \end{enumerate}
    
        \subsection{Applications linéaires}  % Applications linéaires
        
            \begin{mdframed}[linecolor=blue]
                \textcolor{blue}{\textbf{Définition :}}\\
                Soient E et \texttt{F}, 2 e.v. sur le même corps $\mathbb K$.
                
                Une application $u : E \to \texttt{F}$ est \textbf{linéaire}
                si elle préserve les structures vectorielles, c'est a dire les propriétés suivantes :
                
                \[
                    \left \{
                        \begin{aligned}
                            u(x + y) &= u(x) + u(y) \; \forall x, y \in E\\
                            u(\lambda \cdot x) &= \lambda \cdot u(x) \; \forall \lambda \in \mathbb K, x \in E
                        \end{aligned}
                    \right.
                \]
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
                \textcolor{green}{\textbf{Exemple :}}\\
                Les application suivantes sont elles linéaires?
                
                \begin{itemize}
                    \item $a : \mathbb R^2 \rightarrow \mathbb R^2 : (x, y) \mapsto (y, x)$ 
                    \item $b : \mathbb R^2 \rightarrow \mathbb R^2 : (x, y) \mapsto (\sin(x), y)$
                \end{itemize}
                
                1) Si $a$ est linéaire, elle doit respecter les 2 propriétés énoncées plus haut.
                Vérifions la première : $a(x + y) \stackrel{?}{=} a(x) + a(y)$.
                
                Considérons $(x, y)$ et $(v, w)$, 2 antécédents de $a$.
                Pour vérifier la première propriété, il faut que $a((x, y) + (v, w)) = a(x, y) + a(v, w)$.
                Développons des 2 côtés:
                
                (Gauche) $a((x, y) + (v, w)) = a(x + v, y + w)$
                
                Maintenant on applique $a$ qui va intervertir les coordonnées.
                
                $a(x + v, y + w) = (y + w, x + v)$
                
                (Droite) $a(x, y) + a(v, w) = (y, x) + (w, v) = (y + w, x + v)$.

                Le coté gauche de l'équation est égal au coté droit, donc la première propriété est démontrée.
                Maintenant il nous faut démontrer la seconde propriété :
                $a(\lambda \cdot x) \stackrel{?}{=} \lambda\cdot a(x)$
                
                On choisit un couple $(x, y)$, antécédent de $a$. Une fois encore,
                on vérifie en développant des 2 côtés et on regarde s'ils sont égaux.
                Donc si $a(\lambda \cdot (x, y))= \lambda \cdot a(x, y)$.
                
                (Gauche) : $a(\lambda \cdot (x, y)) = a(\lambda x, \lambda y) = (\lambda y, \lambda x)$
                
                (Droite): $\lambda \cdot a(x, y) = \lambda \cdot (y, x) = (\lambda y, \lambda x)$.
                
                Les côtés gauche et droit sont égaux, la seconde propriété est donc respectée.
                Comme les 2 propriétés ont été vérifiées et approuvées, $a$ est linéaire.
                
                2) (Même principe que plus haut, donc voir $a$ pour les détails)
                
                Si $b$ est linéaire elle doit respecter les 2 propriétés énoncées plus haut.
                Vérifions la première: $b(x + y) \stackrel{?}{=} b(x) + b(y)$ et
                donc $b((x, y) + (v, w)) = b(x, y) + b(v, w)$
                
                (Gauche) : $b((x, y) + (v, w)) = b(x + v, y + w) = (\sin(x + v), y + w)$
                
                (Droite) : $b(x, y) + b(v, w) = (\sin(x), y) + (\sin(v), w) = (\sin(x) + \sin(v), y + w)$
                
                Or, $\sin(x + v) \neq \sin(x) + \sin(v) \forall x, v \in \mathbb R$,
                donc l'égalité est fausse. Comme nous avons une contradiction
                il n'est pas utile de vérifier la seconde propriété. $b$ n'est
                pas linéaire. Il suffit de trouver un \textbf{contre-exemple}
                pour prouver qu'une hypothèse est fausse.
                Si l'on en trouve pas, il faut démontrer que les propriétés marchent dans notre cas.
                (Voir première séance d'exercice pour plus d'exercice sur les applications linéaires)
            \end{mdframed}

            \begin{mdframed}[linecolor=cyan]
                \textcolor{cyan}{\textbf{Remarque :}}\\
                Si $u : E \rightarrow F$ est une application linéaire, alors
                $u(0_E)=0_F$. Autrement dit, si le domaine de l'application ne
                contient pas l'élément neutre, alors elle est d'office pas linéaire
                (\textbf{Attention} cette affirmation n'est pas tout le temps vraie dans l'autre sens !).
            \end{mdframed}

            \bigskip
            
            \begin{mdframed}[linecolor=red]
                \textcolor{red}{\textbf{Théorème :}}\\
                Soit $A$, un ensemble quelconque, soit E un $\mathbb K$-e.v.\\
                On écrit $E^A = \{u : A \to E\}$
                l'ensemble des applications allant de $A$ dans $E$. $E^A$ a une structure vectorielle.
            \end{mdframed}

            \bigskip
            
            \begin{mdframed}[linecolor=blue]
                \textcolor{blue}{\textbf{Définition :}}\\
                Une application linéaire qui est bijective (injective et surjective) est appelée \textbf{isomorphisme}.
                
                Rappel pour $f : E \rightarrow F$ :
                
                \begin{itemize}
                    \item f est injective $\Leftrightarrow$ il n'existe pas 2 points qui ont la même image.
                          Autrement dit, $f(v) = f(w) \Rightarrow v = w$. \\
                          ex : $f : \mathbb R \rightarrow \mathbb R : x \mapsto x^2$
                          n'est pas injective sur $\mathbb R$ car pour $f(x) = 1$, on a
                          $x^2 = 1 \Leftrightarrow x \in \{-1, 1\}$,
                          mais elle est injective sur $\mathbb R^+$ ;
                    \item f est surjective $\Leftrightarrow$ tout les points de l'ensemble des images sont atteints.
                          Autrement dit, $\forall w \in F, \exists v \in E t.q. \; f(v) = w$. \\
                          ex : $f: \mathbb R \rightarrow \mathbb R : x \mapsto  x^2$
                          n'est pas surjective sur l'ensemble image $\mathbb R$ car
                          $\nexists x t.q. \; f^2 = -1$. Mais elle est surjective
                          sur l'ensemble des images $\mathbb R^+$ ;
                    \item f est bijective $\Leftrightarrow$ l'application est à la fois injective et surjective.
                          ex : $f : \mathbb \rightarrow \mathbb R : x \mapsto x^3$.
                \end{itemize}
                
                Avec un schéma: \\
                \includegraphics[scale=0.475]{figures/bijection.png}
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
                \textcolor{green}{\textbf{Exemple :}} \\
                Comment prouver qu'une application est bijective?
                
                $u :\mathbb R^3 \to \mathbb R^3 : (x, y, z)\mapsto: (x+y-z, x-y, z)$
                
                Si $u$ est bijective, alors pour $(a, b, c)$ fixé, il existe un
                unique élément $(x, y, z) \in \mathbb R^3$ tel que $u(x, y, z) = (a, b, c)$.
                Nous avons donc un système d'équations !
                
                \[
                    \left \{
                        \begin{aligned}
                            x + y - z &= a \\
                            x - y &= b\\
                            x &= c
                        \end{aligned}
                    \right.
                \]
                \[
                    \left \{
                        \begin{aligned}
                             x &= c \\
                             y &= -b + c\\
                             z &= -a - b + 2c
                        \end{aligned}
                    \right.
                \]
                
                Il existe donc qu'une et une seule solution au système, donc l'application $u$ est bijective.
                Si elle est également linéaire (ce qu'elle est, la démonstration est laissée en exercice),
                alors $u$ est un isomorphisme.
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
                \textcolor{red}{\textbf{Théorème :}} \\
                $\mathbb K^{\{0, 1\}} \sim \mathbb K^2 $ ($\sim$ veut dire \textit{est comparable à}),
                c'est-à-dire qu'il existe un \textbf{isomorphisme canonique} :
                $\phi : \mathbb K^{\{0, 1\}} \to \mathbb K^2$.
                
                Soit $A$ un ensemble fini : \#$A$ = $n$ \quad(\# = cardinal = nombre d'éléments).
                $\mathbb K^A \sim \mathbb K^n \longrightarrow$ ils sont canoniquement isomorphes.
            \end{mdframed}

        \subsection{Sous-espaces vectoriels}  % Sous-espaces

            \begin{mdframed}[linecolor=blue]
                \textcolor{blue}{\textbf{Définition :}} \\
                Soit $E$ un $\mathbb K$-e.v. et $F \subset E$, un sous-ensemble de E.
                On dit que $F$ est un \textbf{sous-espace vectoriel} de E si et seulement si :
                
                \[
                    \left \{
                        \begin{aligned}
                            v + w \in F \qquad &\forall v, w \in F, v + w \in F \\
                            \lambda \cdot v \in F \qquad &\forall \lambda \in \mathbb K, v \in F 
                        \end{aligned}
                    \right.
                \]
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
                \textcolor{red}{\textbf{Théorème :}} \\
                Soit $\{v\}$ où $v \neq 0_E$ n'est \textbf{pas} un e.v : $v + v = 2v \neq v$.
                Alors : $F = \{\lambda \cdot v \quad t.q. \; \lambda \in \mathbb K \}$ est sous-e.v. de E.
                On l'appelle également \textit{droite vectorielle de $E$ engendrée par $v$}.
            \end{mdframed}

            \begin{mdframed}[linecolor=magenta]
                \textcolor{magenta}{\textbf{Notation :}}\\
                On note la droite vectorielle $\{\lambda \cdot v \quad t.q. \; \lambda \in \mathbb K \}$
                de la manière suivante : $v \mathbb K$.
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
                \textcolor{green}{\textbf{Exemple :}} \\
                Pour $E = \mathbb R^2$, les sous-ensembles $F_i$ ci dessous
                sont-ils des sous-espaces vectoriels de $E$ ?
                \begin{itemize}
                    \item $F_1 = \{(x, y) \in \mathbb R^2 \quad t.q. \; 3x+2y=0\}$
                    \item $F_2 = \{(x, y) \in \mathbb R^2 \quad t.q. \; x^2+y^2=1\}$
                    \item $F_2 = \{(x, y) \in \mathbb R^2 \quad t.q. \; 3x+2y=1\}$
                \end{itemize}
                
                Sur un graphique: \\
                \includegraphics[scale=0.5]{figures/fonctions.png}
                
                1) $F_1$ est-il un sous-e.v. ?\\
                \begin{itemize}
                    \item soit $(x, y)$ et $(x', y')$ dans $F_1$, est-ce que
                          $(x, y) + (x', y') \in F_1$ ? $(x, y) + (x', y') = 3(x + x') + 2(y+y') = 3x + 3x' + 2y + 2y' = (3x + 2y) + (3x' + 2y') = 0 + 0 = 0 \in F_1$
                          étant donné que $3x + 2y = 0$ est notre "équation" de départ (voir énoncé).
                          La première propriété pour que $F_1$ soit un sous-e.v. de $E$ est donc vérifiée ;
                    \item soit $(x, y) \in F_1$ et $\lambda \in \mathbb R$, est-ce que
                          $\lambda(x, y) \in F_1$? $\lambda(x, y) = 3(\lambda x) + 2(\lambda y) = \lambda(3x + 2y) = \lambda 0 = 0 \in F_1$.
                          La seconde propriété est vérifiée également, donc $F_1$ est un sous-e.v. de $E$.
                          Nous pouvons aussi dire que $3x + 2y = 0$ est une droite vectorielle de E.
                \end{itemize}
                
                2) Prenons les points $(1, 0)$ et $(0, 1) \in F_2$.
                $(1, 0) + (0, 1) = (1, 1) \notin F_2$, car $1^2 + 1^2 = 2 \neq 1$.
                Donc grâce à un contre-exemple, nous pouvons affirmer que $F_2$ n'est pas un sous-e.v de $E$.
                
                3) Idem que pour le 2) avec les points $(1, -1)$ et $(3, -4)$
            \end{mdframed}

            \begin{mdframed}[linecolor=cyan]
                \textcolor{cyan}{\textbf{Remarque :}} \\
                Si $F$ est un sous-ensemble de $E$, alors $0_E \in F$.
                Autrement dit, si le sous-ensemble $F$ ne contient pas l'élément neutre
                de l'ensemble $E$ auquel il appartient, il n'est pas un sous e.v de cet ensemble.
                (Cette remarque aurait pu permettre de résoudre le 2) et 3) de l'exemple juste au dessus).
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
                \textcolor{red}{\textbf{Théorème :}} \\
                Si $F_1$ et $F_2$ sont des sous-e.v. de E, alors $F_1 \cap F_2$
                est un sous-e.v. (attention, $F_1 \cup F_2$ ne l'est pas forcément).
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
                \textcolor{green}{\textbf{Exemple :}}\\
                Soient $F_1 = \{(x, y) \in \mathbb R^2 \quad t.q. \; x = 0 \}$ et
                $F_2 = \{(x,y) \in \mathbb R^2 \quad t.q. \; y = 0 \}$. \\
                \includegraphics[scale=0.6]{figures/vecteurs.png}\\
                $F_1 \cap F_2$ est ici l'intersection des droites $x = 0$ et $y = 0$ qui est le singleton (ensemble de cardinal = 1)
                $(0;0)$. L'union ($\cup$) est par exemple la somme du vecteur $v (1, 0)$ et $w (0, 1)$.
                $v + w = (1, 1) \notin F_1$ ni $F_2$. Ce n'est donc pas un sous-e.v. de $\mathbb R$.
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
                \textcolor{red}{\textbf{Théorème :}}\\
                Si $(\texttt{F}_i )_{i \in I}$ ($I$ = n'importe quel ensemble) est
                une famille quelconque de sous-e.v., $\bigcap_{i \in I} F_i$ est un sous-e.v.
            \end{mdframed}

            \bigskip
            
            \begin{mdframed}[linecolor=red]
                \textcolor{red}{\textbf{Théorème :}}\\
                Y a t-il une relation entre sous-espace vectoriel et application linéaire?
                
                Soit $u : E_1 \to E_2$, une application linéaire.
                
                \begin{itemize}
                    \item Soit $F_1$, un sous-e.v de $E_1$, $u(F_1) = \{u(v) \quad t.q. \; v \in F_1 \} (\subset E_2)$
                          est un sous-e.v. de $E_2$ ; 
                    \item soit $F_2$, un sous-e.v de $E_2$, $u^{-1}(F_2) = \{v \in E \quad t.q. \; u(v) \in F_2 \}$
                          est sous-e.v de E$_1$
                \end{itemize}
            \end{mdframed}

            \subsubsection{Noyau et image:}
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            L'on définit \textbf{Ker $u$} et \textbf{Im $u$}, comme:\\
            Ker $u = u^{-1} ( \{ 0_{E_2} \} )$ le noyau de $u$ (sous-e.v. de E$_1$)\\
            Im $u = u(E_1)$ l'image de $u$ (sous-e.v. de E$_2$)\\\\
            Autrement dit:\\
            Soit $f$ : E$_1 \to E_2$:\\
            Ker $f$ = \{ $\vec v \in E_1$ tel que $f(\vec v)=\vec 0$ \} se qui signifie concrètement : l'ensemble des éléments qui sont envoyé sur l'élément neutre de l'ensemble d'arrivé.\\
            Im $f$ = \{ $\vec v \in E_2 , \exists \vec u \in E_1$ tel que $f(u)=\vec v$ \} C'est donc le sous-ensemble de E$_2$ contenant toutes les images de tous les éléments de E$_1$ et uniquement ces images.
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}\\
            (Ex 2 fiche 2):\\
            On fixe un vecteur $\vec v_0$ de l'espace tri-dimensionnel. On définit l'application $\Phi_1$ de l'espace des vecteurs de l'espace dans lui-même par $\Phi_1(\vec v) = \vec v \times \vec v_0$. Déterminer le noyau Ker et l'image Im de $\Phi _1$.\\
            2 méthodes possibles:\\
            1) Par calculs:\\
            Soit $ v_0 = (v_{0_x},v_{0_y},v_{0_z} )$ fixé\\
            $\Phi_1 : \mathbb R^3 \to \mathbb R^3: v \mapsto v \times v_0$ produit de 2 vecteurs = produit vectoriel : \\
            \[v \otimes v_0  = \left ( 
            \left| \begin{array}{cc}
            v_y & v_{0_y} \\
            v_z & v_{0_z} \\
            \end{array} \right| 
            ,-
            \left| \begin{array}{cc}
            v_x & v_{0_x} \\
            v_z & v_{0_z} \\
            \end{array} \right| 
            ,
            \left| \begin{array}{cc}
            v_x & v_{0_x} \\
            v_y & v_{0_y} \\
            \end{array} \right| 
            \right ).\]
            = $(v_y \cdot v_{0_z} - v_z \cdot v_{0_y} ; -(v_x \cdot v_{0_z} - v_z \cdot v_{0_x} ); v_x \cdot v_{0_y} - v_y \cdot v_{0_x} ) $
            $\Leftrightarrow$ \[ \left \{
            \begin{array}{l}
            v_y \cdot v_{0_z} - v_z \cdot v_{0_y} = 0 \\
            v_z \cdot v_{0_x} - v_x \cdot v_{0_z} = 0 \\
            v_x \cdot v_{0_y} - v_y \cdot v_{0_x} = 0 \\
            \end{array} \right .
            \Leftrightarrow
            \left \{
            \begin{array}{l}
            v_x =  v_z \cdot \frac{v_{0_x}}{v_{0_z} } \\
            v_y =  v_z \cdot \frac{v_{0_y}}{v_{0_z} } \\
            0 = 0 \\
            \end{array} \right .
            \]
            Nous n'avons donc pas de contraintes pour $v_z$, il vaut donc la valeur qu'on veut (degré de liberté).\\
            $ \texttt{S} = \{ z \cdot \frac{v_{0_x}}{v_{0_z} } ; z \cdot \frac{v_{0_y}}{v_{0_z} } ; z \} = z \cdot \{ \frac{v_{0_x}}{v_{0_z} } ;\frac{v_{0_y}}{v_{0_z} } ; 1 \}$\\
            Ker $\Phi_1 = \mathbb R \{ \frac{v_{0_x}}{v_{0_z} } ;\frac{v_{0_y}}{v_{0_z} } ; 1 \} = \frac {\mathbb R}{v_{0_z}} \{v_{0_x} ;v_{0_y} ; v_{0_z} \}$ qui est une droite vectorielle contenant $v_0$.\\ \\
            2) En utilisant la définition:\\
            Ker $\Phi _1 = \{ \vec v \in \mathbb R^3 | \Phi _1(\vec v) = \vec v \times \vec v_0 = \vec 0 \} = \{ \vec v \in \mathbb R^3 | \vec v = \lambda \cdot \vec v_0 \quad \forall v \in \mathbb R \}$\\ 
            $\vec v = \lambda \cdot \vec v_0$ est une droite vectorielle contenant $\vec v_0$\\ \\
            Im $\Phi_1 = \{ \vec w \in \mathbb R^3 , \exists \vec v \in \mathbb R^3 | \vec w = \vec v \cdot \vec v_0 \}$\\
            $= \{ \vec w \in \mathbb R^3 | \vec w \perp \vec v , \vec w \perp \vec v_0 \}$ ce qui est le plan perpendiculaire à $\vec v_0$.\\
            Oui si : 
            \[ \left \{
            \begin{array}{l}
            x = a+2b\\
            y = 2a+3b\\
            \end{array}
            \right .
            \Leftrightarrow
            \left \{
            \begin{array}{l}
            a = 2x-y\\
            b = -3x+2y\\
            \end{array}
            \right .
            \]
            possible $\forall(x;y)$
            \end{mdframed}

            \subsubsection{Combinaison linéaire:}
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Soit : $v_1,\ldots ,v_n \in E$ (vecteurs)\\
            et :  $\lambda_1, \ldots ,\lambda_n \in \mathbb K$ (scalaires)\\
            On dit que $\sum\limits_{i=1}^n \lambda_i v_i = \lambda_1v_1 + \ldots + \lambda_iv_i $ est une \textbf{combinaison linéaire} (c.l.) des vecteurs  $v_1, \ldots ,v_n$\\
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            $u: E_1 \to E_2$ est linéaire, se qui est signifie que pour toute c.l. $\sum\limits_{i=1}^n \lambda_i v_i  : u\bigg( \sum\limits_{i=1}^n \lambda_i v_i \bigg) = \sum\limits_{i=1}^n \lambda_i \ u(v_i)$\\\\
            \texttt{F} $\subset$ E (avec E e.v. et \texttt{F} sous-e.v), signifie que toute c.l. de \texttt{F}  est dans $(\ v_1-v_n \in \texttt{F}_1 \ \lambda_1-\lambda_n \in \mathbb K$, alors $\sum\limits_{i=1}^n \lambda_i v_i  \in $ \texttt{F} )
            \end{mdframed}

            \bigskip
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Soit \texttt{F} sous e.v.\\
            Vect A (aussi noté $<$A$>$) = $\underset{A\subset \texttt{F}}{\cap} F \overset{lemme}{=} \sum\limits^n_{i=1} \lambda_i v_i ;v_1,\cdots,v_n \in A ; \lambda_1,\cdots,\lambda_n \in \mathbb K$ toutes les c.l de A.\\
            Autremend dit: Vect A est l'ensemble des c.l. de vecteurs de A. $\vec v$ appartient à Vect A si et seulement s'il existe une famille finie de scalaires $\lambda_i$ et telle que $\vec v = \sum\limits_{a\in A} \lambda_a \cdot a$\\
            Vect A est sous e.v. de E, on l'appelle l'\textbf{espace vectoriel engendré} par A. \\
            Soit A et B 2 sous-ensembles de E. A = B $\Leftrightarrow$ A $\subset$ B et B $\subset$ A
            \end{mdframed}

            \subsubsection{Famille génératrice:} % Famille génératrice
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Soit A $\subset$ E, on dit que A est une \textbf{famille génératrice} (ou partie génératrice) si Vect A = E.\\
            Autrement dit, $\forall v \in E, \exists $ une c.l. (finies) de vecteurs de A tels que $v = \sum\limits_{i=1}^n \lambda_i v_i , v_1; \cdots ; v_n \in$ A
            \end{mdframed}

            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Lemmes:}}
            \begin{itemize}
             \item Si A est génératrice et A $\subset$ B, alors B est génératrice.
             \item Soit A une famille génératrice et $v \in$ A, alors A$\setminus \{ v \}$ est génératrice si et seulement si $v$ est une c.l. de vecteurs de A$\setminus \{ v \}$
            \end{itemize}
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}\\
            Soit E = $\mathbb R^3$\\
            La famille a = $\{ (0;1;0);(0;0;1);(1;1;1) \}$ est elle génératrice?\\
            Soit un vecteur quelconque $(a;b;c)$, existe t'il une solution telle que : \\
            $(a;b;c) \stackrel{?}{=} x\cdot(0;1;0) + y\cdot(0;0;1)+z\cdot(1;1;1)$ \\
            Ce qui est équivalent à trouver une solution au système: \\
            \[ \left \{
            \begin{array}{l}
            z = a\\
            x+z = b\\
            y+z = c\\
            \end{array}
            \right .
            \Leftrightarrow
            \left \{
            \begin{array}{l}
            x = b-a\\
            y = c-a\\
            z = a\\
            \end{array}
            \right .
            \]
            L'on remarque qu'il manque à a le vecteur canonique $(1;0;0)$ pour qu'elle soit une famille génératrice. Mais peut-être que ce vecteur manquant peut s'écrire comme combinaison linéaire des autres (et du coup a serai une famille génératrice). Et donc : \\
            $(1;0;0) \stackrel{?}{=} x\cdot(0;1;0) + y\cdot(0;0;1)+z\cdot(1;1;1)$\\ et en reprenant le système  au-dessus et en remplaçant $a,$ $b$ et $c$ par 1, 0 et 0, on trouve:\\
            \[ \left \{
            \begin{array}{l}
            x = 0-1\\
            y = 0-1\\
            z = 1\\
            \end{array}
            \right .
            \Leftrightarrow
            \left \{
            \begin{array}{l}
            x = -1\\
            y = -1\\
            z = 1\\
            \end{array}
            \right .
            \]
            Donc d'après le 2eme lemme a est une famille génératrice.\\
            Remarque: si l'on remplace dans l'égalité les résultats de $x$, $y$ et $z$ trouvé dans le système, on retrouve le vecteur manquant.\\
            $(1;0;0) \stackrel{?}{=} x\cdot(0;1;0) + y\cdot(0;0;1)+z\cdot(1;1;1)$\\
            $(1;0;0) \stackrel{?}{=} (-1)\cdot(0;1;0) + (-1)\cdot(0;0;1)+1\cdot(1;1;1)$\\
            $(1;0;0) \stackrel{?}{=} (0;-1;0) + (0;0;-1)+(1;1;1)$\\
            $(1;0;0) \stackrel{?}{=} (1;0;0)$
            \end{mdframed}

            \subsubsection{Famille libre/liée:} % Famille génératrice
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Soit a $\subset$ E sous-ensemble de E\\
            On dit que a est \textbf{libre} si la seule c.l. de vecteurs de a égale à $\overrightarrow{0_E}$ est la c.l. triviale.\\
            C'est à dire si $\sum\limits_{i=1}^n \lambda_i v_i = \overrightarrow{0_E}, v_1; ... ; v_n \in a\Rightarrow \lambda_1 = 0;...; \lambda_n = 0$\\
            Si elle n'est pas libre, elle est \textbf{liée}.
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}
            \begin{enumerate}
             \item E = $\mathbb R^2$, a = \{ (-2;3) ; (2;-3) \}\\
                 a est liée car $1\cdot\vec v_1 + 1\cdot\vec v_2 = 1\cdot(-2;3) + 1\cdot(2;-3) = (-2;3)+(2;-3) =  	 (0;0) = \overrightarrow{0_E}$\\
                 a est donc liée car on a trouvé $\lambda_1 = \lambda_2 = 1 \neq 0$
            \item E = $\mathbb R^3$, \texttt{A'} = \{ (1;1;3) ; (5;2;-1) ; (4;1;-4) \}\\
                 \texttt{A'} est liée aussi car  $\vec v_1 - \vec v_2 + \vec v_3 = \overrightarrow{0_E}$\\
                 \texttt{A'} est donc liée car on a trouvé $\lambda_1 = \lambda_3 = 1 \neq 0$ et $\lambda_2 = -1 \neq 0$
            \item E = $\mathbb R^3$, \texttt{A''} = \{ (1;1;3) ; (5;2;-1) \}\\
                A vu d'oeil on ne sait pas dire donc on résout le systèmes, il faut donc essayer de trouver une c.l. des éléments de \texttt{A''} pour trouver le $\overrightarrow{0_E}$. C'est à dire:\\
                $\lambda_1\cdot(1;1;3) + \lambda_2\cdot(5;2;-1) = \overrightarrow{0_E}$ = (0;0;0)\\
                Ce qui revient à résoudre le système:
                \[ \left \{
                \begin{array}{l}
                \lambda_1 + 5\cdot\lambda_2 = 0\\
                \lambda_1 + 2\cdot\lambda_2 = 0\\
                3\cdot\lambda_1 - \lambda_2 = 0\\
                \end{array}
                \right .
                \Leftrightarrow
                \left \{
                \begin{array}{l}
                \lambda_1 = -5\cdot\lambda_2\\
                \lambda_1 = -2\cdot\lambda_2\\
                \lambda_1 = \frac{\lambda_2}{3}\\
                \end{array}
                \right .
                \Leftrightarrow
                \lambda_1 = \lambda_2 = 0\\
                \]
                Donc \texttt{A''} est libre!
            \end{enumerate}
            Si on avait essayé de résoudre le système du 2. on aurait obtenu le calcul suivant:\\
            \[ \left \{
            \begin{array}{l}
            \lambda_1 + 5\cdot\lambda_2 + 4\cdot\lambda_3= 0\\
            \lambda_1 + 2\cdot\lambda_2 + \lambda_3= 0\\
            3\cdot\lambda_1 - \lambda_2 - 4\cdot\lambda_3= 0\\
            \end{array}
            \right .
            \Leftrightarrow
            \left \{
            \begin{array}{l}
            \lambda_1 = \lambda_3\\
            \lambda_2 = -\lambda_3\\
            \end{array}
            \right .
            \Leftrightarrow
            \lambda_1 = -\lambda_2 = \lambda_3\\
            \]
            Donc $\forall \lambda, \lambda\cdot \vec v_1- \lambda\cdot\vec v_2 + \lambda\cdot\vec v_3 = \overrightarrow{0_E}$\\
            La réponse (contrexemple) que nous avions trouvé : $\vec v_1 - \vec v_2 + \vec v_3 = \overrightarrow{0_E}$ correspondant au vecteur (1;-1;1) et correspond donc bien à une de nos réponses aux systèmes (avec $\lambda$ = 1)
            \end{mdframed}

            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Si a est libre, on dira que les vecteurs de a sont \textbf{linéairement indépendant} (l.i),
            si a n'est pas libre (liée), alors on dira que ses vecteurs sont \textbf{linéairement dépendant} (l.d.)
            \end{mdframed}

            \begin{mdframed}[linecolor=cyan]
            \textcolor{cyan}{\textbf{Remarque:}}\\
            Si $\overrightarrow{0_E} \in a$, a ne peux pas être libre (donc elle est d'office liée).\\
            Car $\lambda\cdot\overrightarrow{0_E}=\overrightarrow{0_E} \qquad \forall \lambda \neq 0$
            \end{mdframed}

            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Lemme:}}\\
            Soit a partie de E:
            \begin{itemize}
             \item a est liée, a $\subset$ \texttt{B}, \texttt{B} est liée
             \item a est libre, \texttt{B} $\subset$ a, \texttt{B} est libre
             \item a est libre, $v \in$ vect(a), alors il existe une unique c.l.de vecteurs de a égale à $v$.
                      Autrement dit: $\exists (v_1;...;v_n) \in a, v = \sum\limits_{i=1}^n \lambda_i v_i$
             \item a est libre, $v \in$ E, alors a $\cup \{ v\}$ est libre $\Leftrightarrow v \in$ vect(a)
            \end{itemize}
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            \[ \mathrm{Si\ a\  est\  libre:}
            \left \{
               \begin{array}{l}
                  \mathrm{Si \ } v \in a,\  a\setminus \{ v \} \mathrm{\ est\ libre} \\
                  \mathrm{Si \ } v \notin a,\  a\cup \{ v \} \mathrm{\ est\ libre} \Leftrightarrow v \notin \mathrm{vect(a)} \\
               \end{array}
            \right .\]
            \[ \mathrm{Si\ a\  est\  generatrice:}
            \left \{
               \begin{array}{l}
                  \mathrm{Si \ } v \notin a,\  a\cup \{ v \} \mathrm{\ est\ generatrice} \\
                  \mathrm{Si \ } v \in a,\  a\setminus \{ v \} \mathrm{\ est\ generatrice} \Leftrightarrow v \in \mathrm{vect(a)} \\
               \end{array}
            \right .\]
            $v \in$ vect(a) : autrement dit : s'il existe dans a une c.l. de $v$ qui ne soit pas $v$

            \end{mdframed}

            \subsubsection{Bases et dimensions}  % Bases & dimensions 
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Soit \texttt{B} $\subset$ E une partie de E.\\
            Si \texttt{B} est libre et génératrice on dit que \texttt{B} est une \textbf{base}.\\
            Soit E un e.v. alors E admet une base (et en fait beaucoup).\\
            Toutes les bases de E ont le même nombre d'éléments. C'est la \textbf{dimension} de E
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}
            \begin{itemize}
             \item dim($\mathbb R^n$) = $n$
             \item dim($\mathbb R^\mathbb N$) = $\infty$ (car $\mathbb N$ à une infinité d'éléments)
             \item $v \in E, v \neq 0 $ dim($\mathbb K_v$) = dim(vect(\{$v$\})) = 1  (que $\vec v$)
             \item dim(\{ $\overrightarrow{0_E}$ \}) = 0 (par convention)
            \end{itemize}
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            Si a est libre, il existe \texttt{B} telle que a $\subset$ \texttt{B}, avec \texttt{B} une base.\\
            Inversement, si a est génératrice, il existe une base \texttt{B} contenue dans a.\\
            Autrement dit une famille qui serai libre/génératrice mais qui ne serai pas génératrice/libre, peux devenir une base (donc libre et génératrice), à condition qu'on rajoute/enlève des vecteurs correctement.
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}\\
            a = \{(1 ; 0 ; 0)\} $\rightarrow$ est libre (mais pas génératrice, on va donc essayé de rajouter des vecteur dans a pour que ca devienne générateur (en restant libre))\\
            a' = \{(1 ; 0 ; 0) ; (1 ; 5 ; 3)\} $\rightarrow$ est encore libre (mais toujours pas génératrice)\\
            a''= \{(1 ; 0 ; 0) ; (1 ; 5 ; 3) ; (2 ; 5 ; 3)\} $\rightarrow$ n'est plus libre (il existe une c.l : $v_3 = v_1 + v_2$). Il faut donc faire attention au vecteurs que l'on rajoute, car même si la famillle était génératrice, elle ne serai pas une base car a'' n'est plus libre\\ \\
            a = \{(1 ; 0 ; 0) ; (0 ; 1 ; 0) ; (0 ; 0 ; 1) ; (1 ; 1 ; 1) ; (4 ;  3 ; 21)\} $\rightarrow$ est génératrice (mais pas libre par ex: $v_4 = v_1 + v_2 + v_3$), on va donc essayer d'enlever des vecteurs de a pour que cela devienne libre, tout en restant génératrice.\\
            a' = \{(1 ; 0 ; 0) ; (0 ; 1 ; 0) ; (0 ; 0 ; 1) ; (1 ; 1 ; 1)\} $\rightarrow$ est encore génératrice (mais toujours pas libre)\\
            a'' = \{(1 ; 0 ; 0) ; (0 ; 1 ; 0) ; (0 ; 0 ; 1)\} $\rightarrow$ est génératrice et libre, c'est donc une base.
            \end{mdframed}

            \subsubsection{Relation d'équivalence} % Petite parenthèse sur la théorie des ensembles - Relation d'équivalence
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Une \textbf{relation d'équivalence} dans un ensemble a (quelconque) est une \textbf{relation binaire} (relation entre paires d'éléments) de a, notée $\sim$.\\
            Elle est :
            \begin{enumerate}
             \item \textbf{Réfléxive} : $ x \sim x \quad \forall x \in a$\\
             {\it(tout le monde est ami avec soi-même)}
             \item \textbf{Symétrique} : si $ x \sim y$ alors $ y \sim x \quad \forall x,y \in a$\\
             {\it(si je suis ami avec A, alors A est ami avec moi aussi)}
             \item \textbf{Transitive} : si $x \sim y$ et $y \sim z$ alors $x \sim z \quad \forall x,y,z \in a$\\
             {\it(les amis de mes amis, sont mes amis)}
            \end{enumerate}
            \begin{center}
            \includegraphics[scale = 0.66]{figures/equiv.png}
            \end{center}
            \end{mdframed}

            \begin{mdframed}[linecolor=magenta]
            \textcolor{magenta}{\textbf{Notation:}}\\
            $x \sim_p y$ s'écrit aussi communément $x \equiv y[p]$
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}\\
            La relation "être parallèle" (//) est une relation d'équivalence pour l'ensemble E des droites du plans.
            \begin{enumerate}
              \item Réflexivité : Toutes les droites sont parallèles à elle-même
              \item Symétrie : Si D // D' alors D' // D
              \item Transitivité : Si D // D' et que D' // D'' alors D // D''
            \end{enumerate}

            Soit $p \in \mathbb N^*$. On dira que deux nombres entiers relatifs $x$ et $y$ sont congrus modulo $p$ et on notera: $x \equiv y[p]$ si $x-y$ est un multiple de $p$. Prouver qu'il s'agit d'une relation d'équivalence et qu'il y a exactement $p$ classes d'équivalences. \\
            \\
            $x \equiv y[p]$ si $x-y$ est un multiple de $p$. Revient au même que : si $p$ divise $x-y$\\
            Si c'est une classe d'équivalences, alors elle respecte les 3 propriétés:
            \begin{enumerate}
              \item Réflexivité : $x \sim x$\\
              $x \stackrel{?}{\equiv}  x[p] \rightarrow x-x = 0$ (qui est bien un multiple de $p$)
              \item Symétrie : $x \sim y \Rightarrow y \sim x $\\
              $x \equiv y[p] \stackrel{?}{\Rightarrow} y \equiv x[p]$\\
              $x \equiv y[p] \rightarrow x-y$ multiple de p\\
              $y \equiv x[p] \rightarrow y-x$ multiple de p ? $y-x = -1\cdot(x-y)$ qui sont tout 2 multiple de $p$ OU si $p$ divise $x-y$ alors $p$ divise aussi $y-x$
              \item Transitivité : $x \sim y$ et $y \sim z \Rightarrow x \sim z$\\
               $x \sim y \rightarrow p$ divise $x-y \rightarrow x-y = q_1\cdot p \quad q_1 \in \mathbb Z$\\ 
               $y \sim z \rightarrow p$ divise $y-z \rightarrow y-z = q_2\cdot p \quad q_2 \in \mathbb Z$\\
               En sommant les 2 équations :\\
               $(x-y)+(y-z) = (q_1\cdot p) + (q_2 \cdot p) \Leftrightarrow x-z = p\cdot(q_1 + q_2)$\\
               Or $x \sim z \rightarrow x-z = p \cdot q_3 \rightarrow q_3 = (q_1+q_2)$ qui est multiple de $p$\\
            \end{enumerate}
            Il s'agit donc bien d'une relation d'équivalence
            \end{mdframed}

            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Soit a muni d'une \textbf{classe d'équivalence} $\sim$.\\
            La classe d'un élément $x\in a$ est le sous-ensemble de a défini par : $[x]_N = \{ y \in a \ | \  x \sim y \}$\\
            \begin{center}
            \includegraphics[scale = 0.66]{figures/equiv2.png}
            \end{center}
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}\\
            (Classes d'équivalences des exemple précédent)\\
            Le parallélisme, sur l'ensemble des droites du plan à comme classe les directions.\\
            \\
            Sur l'ensemble $\mathbb Z$ des entiers relatifs, la congruence modulo $n$ (pour un entier $n$ fixé) est une relation d'équivalence, dont les classes forment le groupe cyclique $\mathbb Z/n\mathbb Z$. Qui correspond à : \\
            \{ $x+p\ ;\ x + 2p\ ;\ ...\ ;\ x - p\ ;\ x - 2p\ ;\ ... \} = \{ x+kp\ |\  k\in \mathbb Z \} = x + p\mathbb Z $
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            L'ensemble des classes d'équivalences de $\sim$ forme une partition de E.\\
            (a$_i)_{i \in I}$ famille de partie de E : $\forall i \in I ,a_i \subset E$.\\
            On dira que (a$_i)_{ \in I}$ est une partition de E si:
            \begin{itemize}
              \item $a_i \cap a_j = \emptyset \quad$ si $i \neq j$ (pas d'intersection entre les familles) 
              \item $\underset{i\in \texttt{I}}{\cup} a_i = E$ (l'union de toute les familles forme l'ensemble)
            \end{itemize}
            \begin{center}
            \includegraphics[scale = 0.7]{figures/partition.png}
            \end{center}
            \end{mdframed}

            \begin{mdframed}[linecolor=magenta]
            \textcolor{blue}{\textbf{Définition:}}\\
            \{ $[x], x \in a \} = a/\sim $ et est appelé "quotient de a par $\sim$"
            \end{mdframed}

            \begin{mdframed}[linecolor=green]
            \textcolor{green}{\textbf{Exemple:}}\\
            (Avec le modulo de l'exemple précédent)\\
            $\mathbb Z/\sim_p = p$ éléments $:= \mathbb Z / p\mathbb Z$\\
            Pour $p = 2$ on à :  $\mathbb Z / 2\mathbb Z \approx$ \{[0];[1]\} = \{\{ "pairs" (multiples de 2)\ ;\  "impairs"\}\}\\
            Pour $p = 3$ on a donc : \{\{"nombre \% 3 = 0"\ ;\ "nombre \% 3 = 1"\ ;\ "nombre \% 3 = 2 "\}\} (\% est considéré comme le symbole du modulo comme en Python)
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            E/\texttt{F} (l'ensemble des classes d'équivalences) à une structure vectorielle canonique ( E/\texttt{F} est un e.v. sur $\mathbb K$)
            \end{mdframed}

            \begin{mdframed}[linecolor=cyan]
            \textcolor{cyan}{\textbf{Remarque:}}\\
            Une autre relation d'équivalence:\\
            Soient a et \texttt{B} 2 ensembles, on dira que a et \texttt{B} ont "le même cardinal" s'il existe une bijection $f:a\rightarrow \texttt{B}$ noté: \#a = \#\texttt{B} (et revient en gros au nombres d'éléments de l'ensemble).
             \end{mdframed}

            \begin{mdframed}[linecolor=magenta]
            \textcolor{magenta}{\textbf{Notation:}}\\
            Si \#a = \#\{1 ; ... ; $n$\} on dira que A est fini et on notera \#a = $n$
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            On dira que \#a $\leq$ \#\texttt{B} s'il existe une injection $f : a \to \texttt{B}$\\
            Contor-Bernstein : Si \#a $\leq$ \#\texttt{B} et \#\texttt{B} $\leq$ \#a alors \#a = \#\texttt{B}
            \end{mdframed}

            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            Si \#a = \#$\mathbb N$, on dit que a est \textbf{dénombrable}\\
            Si \#a = \#$\mathbb R$, on dit que a à la puissance du continu
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Propriétés:}}
            \begin{itemize}
             \item Si \#a $\leq \#\mathbb N$, soit a est fini, soit a est dénombrable
             \item Si \#a = $n$, \#(P(a)) = $2^n$ \ \ (P(a) = \{ sous-ensemble de a \})
             \item Si \#a = $n$ et \#\texttt{B} = $m$, \#(\texttt{B}$^a) = m^n = \#\texttt{B}^{\#a} \quad (\texttt{B}^a = \{ f : a \to \texttt{B} \})$
             \item $\# \mathbb Z = \# \mathbb N$ (en pouvant, par exemple, associé les éléments pairs des éléments de $\mathbb N$ aux éléments positifs de $\mathbb Z$ et ls impaires aux négatifs (Voir scan théorique page 17 pour détails)), du coup $\mathbb Z$ est dénombrable, $\mathbb N^2$ aussi et également $\mathbb Q$.
             \item Mais $\mathbb R$ n'est pas dénombrable, autrement dit : il n'existe pas de bijection : $f : \mathbb N \to \{0\ ;\ ...\ ;\ 9\}^\mathbb N \Rightarrow \#\{0\ ;\ ...\ ;\ 9\}^\mathbb N > \#\mathbb N$
             \end{itemize}
            \end{mdframed}

            \subsubsection{Retour sur Bases et dimensions}
            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Rappel:}}\\
            Soit E un e.v sur $\mathbb K$. Alors il existe de(s) base(s) noté $B$, $B'$, $B''$, ... .\\
            \#$B$ est appelé dimension de E\\
            S'il existe une famille génératrice finie dans E, on dit que E est de \textbf{dimension finie}
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            Si j'ai 2 bases $B$ et $B'$ de E, alors \#$B$ = \#$B'$.
            \end{mdframed}

            \bigskip

            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Rappel:}}\\
            Soit E$_2$ un e.v sur $\mathbb K$.\\ 
            E$_2^{E_1} = \{ f : E_1 \rightarrow E_2 \}$ est un e.v. sur $\mathbb K$ on suppose de plus que E$_1$ est un e.v. sur  $\mathbb K$.
            \end{mdframed}

            \begin{mdframed}[linecolor=blue]
            \textcolor{blue}{\textbf{Définition:}}\\
            L(E$_1, E_2) \subset  E_2^{E_1}$, L(E$_1, E_2) = \{ u : E_1 \rightarrow E_2 | u $ linéaire, c'est à dire: $u(\lambda\cdot v + w) = \lambda u(v) + u(w) \}$
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorèmes:}}\\
            \begin{itemize}
             \item L(E$_1$, E$_2$) est un sous e.v. de E$_2^{E_1}$
             \item Si dim(E$_1) <  +\infty$ et dim(E$_2) <  +\infty$, dim(L(E$_1, E_2$)) = dim(E$_1) \times$ dim(E$_2$)
             \item Si \#a $< +\infty$ et E un e.v. de dimension finie: dim(E$^a$) = (dim(E))$^{\#a}$
            \end{itemize}
            \end{mdframed}

            \begin{mdframed}[linecolor=red]
            \textcolor{red}{\textbf{Théorème:}}\\
            Soit E un e.v. sur $\mathbb K$, $B=\{ e_1\ ;\ ...\ ;\  e_n\}$ base de E, dim(E) = $n$\\
            $\phi: \mathbb K^n \rightarrow E$\\
            $(\lambda_1 \  ;\  ...\ ;\ \lambda_n) \mapsto \sum\limits_{i=1}^n \lambda_i e_i$ alors $\phi$ est un isomorphisme
            \end{mdframed}


        \subsection{Matrices:} % MATRICES

        \begin{mdframed}[linecolor=blue]
        \textcolor{blue}{\textbf{Définition:}}\\
        Soit $u: E \rightarrow E' \quad$ avec E et E' 2 e.v sur $\mathbb K$ avec \\
        $B = \{ e_1\ ;\ ...\ ;\ e_n\}$ base de E\\
        $B' = \{ e'_1\ ;\ ...\ ;\ e'_n\}$ base de E'\\ \\
        $u(\phi(\lambda_1\ ;\ ...\ ;\ \lambda_n)) = \sum\limits_{i, j=1}^{n,m} \lambda_i\ a_{j, i}\ e'_j$ (voir théorème précédent)\\
        On dira que la matrice $M=[a_{j,i}]_{\substack{1 \leq i \leq m \\ 1 \leq j \leq n}} = 
        \begin{pmatrix}
          a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
          a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
          \vdots  & \vdots  & \ddots & \vdots  \\
          a_{m,1} & a_{m,2} & \cdots & a_{m,n}
         \end{pmatrix}$\\
         est la matrice associée à $u$ dans les bases $B$ et $B'$.
        \end{mdframed}

        \begin{mdframed}[linecolor=green]
        \textcolor{green}{\textbf{Exemple:}}\\
        Soit $u: \mathbb R^3 \to \mathbb R^2 \\
        u(x,y,z) = (x+3y-z,y+2z)$\\
        Trouver la matrice associée à $u$.\\ \\
        La base canonique de $\mathbb R^3$ est : \{$e_1, e_2, e_3$\} = \{(1;0;0), (0;1;0), (0;0;1)\}\\
        La base canonique de $\mathbb R^2$ est : \{$e'_1, e'_2$\} = \{(1;0),(0;1)\}\\
        Nous allons trouver les vecteurs de la base canonique de départ, associé à $u$:\\
        $u(e_1) = u((1;0;0)) = (1+3\cdot 0; 0 + 2\cdot 0) =(1;0) = e'_1 \\
        u(e_2) = u((0;1;0)) = (3;1) = 3\cdot e'_1+ e'_2 \\
        u(e_3) = u((0;0;1)) = (-1;2) = -e'_1+2\cdot e'_2 \\$
        La matrice associée à $u$ est les résultats précédents mis en colonnes:\\
        Matrice associée à $u = 
        \bordermatrix{& u(e_1) & u(e_2) & u(e_3) \cr
                     & 1 & 3 & -1 \cr
                              & 0 & 1 & 2 \cr} =
        \begin{pmatrix}
          1 & 3 & -1 \\
          0 & 1 & 2 
         \end{pmatrix}$\\ \\ \\
         Si l'on vérifie dans l'autre sens en utilisant la définition au dessus:
         $u(\lambda_1\ ;\ \lambda_2\ ;\ \lambda_3) = \sum\limits_{i=1}^3 \sum\limits_{j=1}^2 \lambda_i \ a_{j,i}\ e'_j $ qui peut etre interprété (pour les BG informaticiens :D ) comme un \texttt{for} imbriqué en \texttt{Python}.\\
        Si l'on décompose:
        \renewcommand{\labelitemi}{$\bullet$}

        \begin{itemize}
         \item $i =1:$
         \begin{itemize}
          \item $j = 1: \lambda_1\cdot a_{1,1}\cdot e'_1 = \lambda_1\cdot1\cdot(1;0) = (\lambda_1;0)$
          \item $j = 2:  \lambda_1\cdot a_{2,1}\cdot e'_2 = \lambda_1\cdot0\cdot(0;1) = 0$
         \end{itemize}
         \item $i =2:$
         \begin{itemize}
          \item $j = 1: \lambda_2\cdot a_{1,2}\cdot e'_1 = \lambda_2\cdot3\cdot(1;0) = (3\lambda_2;0)$
          \item $j = 2:  \lambda_2\cdot a_{2,2}\cdot e'_2 = \lambda_2\cdot1\cdot(0;1) = (0;\lambda_2)$
         \end{itemize}
         \item $i=3:$
        \begin{itemize}
          \item $j = 1: \lambda_3\cdot a_{1,3}\cdot e'_1 = \lambda_2\cdot(-1)\cdot(1;0) = (-\lambda_3;0)$
          \item $j = 2:  \lambda_3\cdot a_{2,3}\cdot e'_2 = \lambda_2\cdot2\cdot(0;1) = (0;2\lambda_3)$
         \end{itemize}
        \end{itemize}
        La somme des 6 lignes donne: $(\lambda_1+3\lambda_2-\lambda_3;\lambda_2+2\lambda_3)\\
        u(\lambda_1\ ;\ \lambda_2\ ;\ \lambda_3) = (\lambda_1+3\lambda_2-\lambda_3;\lambda_2+2\lambda_3)$
        Ce qui est bien se qu'on avait au départ (en remplaçant les $\lambda$ par $x$, $y$ et $z$)
        \end{mdframed}

        \begin{mdframed}[linecolor=magenta]
        \textcolor{magenta}{\textbf{Notation:}}\\
        Les matrices sont aussi notée Mat$_\mathbb K(m,n)$ avec:\\
        $m$ = nombre de colonnes\\
        $n$ = nombre de lignes
        \end{mdframed}

        \begin{mdframed}[linecolor=red]
        \textcolor{red}{\textbf{Théorème:}}\\
        Les matrices Mat$_\mathbb K(m,n)$ sont des e.v. sur $\mathbb K$.\\
        Chaque matrice à sa "propre" application linéaire qui lui est assciée.
        \end{mdframed}

        \bigskip
        \begin{mdframed}[linecolor=red]
        \textcolor{red}{\textbf{Théorème:}}\\
        Soit $u: E \rightarrow E'$ et $u': E' \rightarrow E''$ avec E, E' et E'' e.v. sur $\mathbb K$.\\
        Si $u \in L(E,E')$ et $u' \in L(E',E'')$, alors $u' \circ u \in L(E,E')$\\
        Soit:\\
        $B = \{ e_1\ ;\ ...\ ;\ e_n\}$ base de E\\
        $B' = \{ e'_1\ ;\ ...\ ;\ e'_n\}$ base de E'\\
        $B'' = \{ e''_1\ ;\ ...\ ;\ e''_n\}$ base de E''\\
        $[a_{i,j}]$ matrice de $u$\\
        $[b_{j,k}]$ matrice de $u'$\\
        $[c_{i,k}]$ matrice de $u' \circ u$\\
        $(u' \circ u)(e_i) = ... = \sum\limits_{k=1}^p (\sum\limits_{j=1}^m \underbrace{a_{i,j}\cdot b_{j,k}}_{c_{i,k}})e''_k$


        \end{mdframed}

\end{document}